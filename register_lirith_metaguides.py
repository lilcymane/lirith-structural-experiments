import os
import textwrap
import time
import chromadb
import openai
from chromadb.utils import embedding_functions
from dotenv import load_dotenv

# âœ… í™˜ê²½ì„¤ì •
load_dotenv()
OPENAI_API_KEY = os.getenv("API_KEY")

# âœ… í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
chroma_client = chromadb.PersistentClient(path="./lirith_chroma")
openai_ef = embedding_functions.OpenAIEmbeddingFunction(
    api_key=OPENAI_API_KEY,
    model_name="text-embedding-3-small"
)
collection = chroma_client.get_or_create_collection(
    name="lirith_metaguides",
    embedding_function=openai_ef
)
openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)

# âœ… í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
def split_text(text, max_chars=4000):
    return textwrap.wrap(text, width=max_chars, break_long_words=False, replace_whitespace=False)

# âœ… ê°œë³„ ì²­í¬ ìš”ì•½ (gpt-4o ì‚¬ìš©)
def compress_chunk_safe(chunk, max_token=300, retries=5, base_wait=10):
    prompt = f"""
ë„ˆëŠ” êµ¬ì¡° ìš”ì•½ê¸°ì•¼. ì•„ë˜ì˜ ë©”íƒ€ì§€ì¹¨ì„ GPT ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ìµœëŒ€í•œ ì••ì¶•í•´ì¤˜.
- í•µì‹¬ ê·œì¹™, ëª¨ë“ˆ ì´ë¦„, êµ¬ì¡°ì  ê¸°ëŠ¥ ìš”ì•½ë§Œ ë‚¨ê²¨.
- ì¥ì‹ ë¬¸ì¥, ë°˜ë³µ ë¬¸ì¥, ë¹„ìœ  í‘œí˜„ì€ ì œê±°í•´.
- ê·œì¹™ ê¸°ë°˜ ì••ì¶•ì´ì•¼. ì˜ë¯¸ ì†ì‹¤ ì—†ì´ {max_token} tokens ì´ë‚´ë¡œ ìš”ì•½í•´.

ìš”ì•½ ëŒ€ìƒ:
===
{chunk}
===
ìš”ì•½ ì‹œì‘:
""".strip()

    for attempt in range(1, retries + 1):
        try:
            response = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=max_token
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if "429" in str(e):
                wait_time = base_wait * attempt
                print(f"â³ [429] Rate limit. {wait_time}s ëŒ€ê¸° í›„ ì¬ì‹œë„... (ì‹œë„ {attempt}/{retries})")
                time.sleep(wait_time)
            else:
                print(f"âŒ GPT ì˜¤ë¥˜ ë°œìƒ: {e}")
                break
    return "[ERROR] ì••ì¶• ì‹¤íŒ¨"

# âœ… ìµœì¢… ë³‘í•© ìš”ì•½ (ì „ì²´ system_prompt ìš”ì•½)
def compress_final_system_prompt(input_text, output_path="system_prompt.txt", max_tokens=4000, retries=5, base_wait=10):
    prompt = f"""
ë„ˆëŠ” GPT ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìµœì í™” ìš”ì•½ê¸°ì•¼. ì•„ë˜ëŠ” ì—¬ëŸ¬ ë©”íƒ€ì§€ì¹¨ ìš”ì•½ì„ ê²°í•©í•œ ê²ƒì´ë‹¤.
- ë°˜ë³µ, ìˆ˜ì‚¬ì  í‘œí˜„, ì˜ˆì‹œëŠ” ì œê±°í•˜ê³  í•µì‹¬ ì›ì¹™ê³¼ ëª…ë ¹ êµ¬ì¡°ë§Œ ë‚¨ê²¨.
- ì˜ë¯¸ ì†ì‹¤ ì—†ì´, ìµœëŒ€ {max_tokens} tokens ì•ˆì— ë‹´ì•„ì•¼ í•´.
- GPT system promptë¡œ ë°”ë¡œ ì í•©í•˜ê²Œ êµ¬ì„±í•´.

ë‚´ìš©:
===
{input_text}
===
ìš”ì•½ ì‹œì‘:
""".strip()

    for attempt in range(1, retries + 1):
        try:
            response = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=max_tokens
            )
            result = response.choices[0].message.content.strip()
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(result)
            print(f"âœ… system_prompt.txt ìµœì¢… ì €ì¥ ì™„ë£Œ (í† í° ìˆ˜ ì¶”ì •: {len(result.split())})")
            return result
        except Exception as e:
            if "429" in str(e):
                wait_time = base_wait * attempt
                print(f"[429] Rate limit. {wait_time}s ëŒ€ê¸° í›„ ì¬ì‹œë„... (ì‹œë„ {attempt})")
                time.sleep(wait_time)
            else:
                print(f"âŒ GPT ì˜¤ë¥˜: {e}")
                break
    return "[ERROR] ìµœì¢… system_prompt ìƒì„± ì‹¤íŒ¨"

# âœ… ë©”íƒ€ì§€ì¹¨ ë“±ë¡ ë° ìš”ì•½ ì €ì¥
def register_safely(meta_files):
    total_summaries = 0
    for filename, doc_prefix, label in meta_files:
        if not os.path.exists(filename):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")
            continue

        with open(filename, "r", encoding="utf-8") as file:
            content = file.read()

        chunks = split_text(content)
        print(f"\nğŸ“„ {label}: {len(chunks)}ê°œ ì²­í¬ ê°ì§€ë¨")

        for i, chunk in enumerate(chunks):
            chunk_id = f"{doc_prefix}_part{i+1}"
            summary_id = f"{doc_prefix}_summary{i+1}"

            try:
                collection.add(
                    documents=[chunk],
                    metadatas=[{"description": f"{label} - íŒŒíŠ¸ {i+1}"}],
                    ids=[chunk_id]
                )
                print(f"âœ… {chunk_id} ì›ë¬¸ ë“±ë¡ ì™„ë£Œ")

                compressed = compress_chunk_safe(chunk)
                if "[ERROR]" not in compressed:
                    collection.add(
                        documents=[compressed],
                        metadatas=[{"description": f"{label} - ìš”ì•½ {i+1}"}],
                        ids=[summary_id]
                    )
                    print(f"ğŸ“ {summary_id} ìš”ì•½ ë“±ë¡ ì™„ë£Œ")
                    total_summaries += 1
                else:
                    print(f"âš ï¸ {chunk_id} ìš”ì•½ ì‹¤íŒ¨")

                time.sleep(15)

            except Exception as e:
                print(f"âŒ {chunk_id} ë“±ë¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    print(f"\nğŸ¯ ìš”ì•½ ë“±ë¡ ì™„ë£Œ. ì´ ìš”ì•½ ìˆ˜: {total_summaries}")

# âœ… ë³‘í•©ëœ ìš”ì•½ ì¬ì •ë¦¬
def compile_summaries_to_system_prompt(output_path="system_prompt.txt"):
    all_texts = []
    for prefix in ["meta_01", "meta_02", "meta_03"]:
        i = 1
        while True:
            doc_id = f"{prefix}_summary{i}"
            try:
                doc = collection.get(ids=[doc_id])
                text = doc['documents'][0].strip()
                all_texts.append(text)
                i += 1
            except:
                break

    merged = "\n\n".join(all_texts)
    print(f"ğŸ“¦ ë³‘í•©ëœ ìš”ì•½ë³¸ ê¸¸ì´ (ì¶”ì • í† í°): {len(merged.split())}")
    compress_final_system_prompt(merged, output_path=output_path)

# âœ… ì‹¤í–‰
if __name__ == "__main__":
    meta_files = [
        ("meta_01.txt", "meta_01", "ë©”íƒ€ì§€ì¹¨ 1ë²ˆ"),
        ("meta_02.txt", "meta_02", "ë©”íƒ€ì§€ì¹¨ 2ë²ˆ"),
        ("meta_03.txt", "meta_03", "ë©”íƒ€ì§€ì¹¨ 3ë²ˆ"),
    ]
    register_safely(meta_files)
    compile_summaries_to_system_prompt()
